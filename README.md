[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/o8XztwuW)
# Proyecto Final 2025-1: AI Neural Network
## **CS2013 ProgramaciÃ³n III** Â· Informe Final

### **DescripciÃ³n**

> ImplementaciÃ³n de una red neuronal multicapa desde cero en C++ para clasificaciÃ³n binaria, sin utilizar bibliotecas de aprendizaje automÃ¡tico externas.

### **ðŸ“¹ Video DemostraciÃ³n**

**[Ver Video Explicativo del Proyecto](https://drive.google.com/drive/folders/124kfF8cgNvq49oHU7IwM7Y30CCYBtBm2?usp=sharing)**

El video incluye:
- ExplicaciÃ³n de la arquitectura de la red neuronal
- DemostraciÃ³n del entrenamiento (XOR y dataset grande)
- AnÃ¡lisis de resultados y mÃ©tricas de precisiÃ³n
- Recorrido por el cÃ³digo fuente

### Contenidos

1. [Datos generales](#datos-generales)
2. [Requisitos e instalaciÃ³n](#requisitos-e-instalaciÃ³n)
3. [InvestigaciÃ³n teÃ³rica](#1-investigaciÃ³n-teÃ³rica)
4. [DiseÃ±o e implementaciÃ³n](#2-diseÃ±o-e-implementaciÃ³n)
5. [EjecuciÃ³n](#3-ejecuciÃ³n)
6. [AnÃ¡lisis del rendimiento](#4-anÃ¡lisis-del-rendimiento)
7. [Trabajo en equipo](#5-trabajo-en-equipo)
8. [Conclusiones](#6-conclusiones)
9. [BibliografÃ­a](#7-bibliografÃ­a)
10. [Licencia](#licencia)
---

### Datos generales

* **Tema**: Redes Neuronales en AI
* **Grupo**: `group_3_custom_name`
* **Integrantes**:

  * Alumno A â€“ 209900001 (Responsable de investigaciÃ³n teÃ³rica)
  * Alumno B â€“ 209900002 (Desarrollo de la arquitectura)
  * Alumno C â€“ 209900003 (ImplementaciÃ³n del modelo)
  * Alumno D â€“ 209900004 (Pruebas y benchmarking)
  * Alumno E â€“ 209900005 (DocumentaciÃ³n y demo)

> *Nota: Reemplazar nombres y roles reales.*

---

### Requisitos e instalaciÃ³n

1. **Compilador**: GCC 11 o superior
2. **Dependencias**:

   * CMake 3.18+
   * Eigen 3.4
   * \[Otra librerÃ­a opcional]
3. **InstalaciÃ³n**:

   ```bash
   git clone https://github.com/EJEMPLO/proyecto-final.git
   cd proyecto-final
   mkdir build && cd build
   cmake ..
   make
   ```

> *Ejemplo de repositorio y comandos, ajustar segÃºn proyecto.*

---

### 1. InvestigaciÃ³n teÃ³rica

* **Objetivo**: Explorar fundamentos y arquitecturas de redes neuronales.
* **Contenido de ejemplo**:

  1. Historia y evoluciÃ³n de las NNs.
  2. Principales arquitecturas: MLP, CNN, RNN.
  3. Algoritmos de entrenamiento: backpropagation, optimizadores.

---

### 2. DiseÃ±o e implementaciÃ³n

#### 2.1 Arquitectura de la soluciÃ³n

* **Patrones de diseÃ±o**: ejemplo: Factory para capas, Strategy para optimizadores.
* **Estructura de carpetas (ejemplo)**:

  ```
  proyecto-final/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ layers/
  â”‚   â”œâ”€â”€ optimizers/
  â”‚   â””â”€â”€ main.cpp
  â”œâ”€â”€ tests/
  â””â”€â”€ docs/
  ```

#### 2.2 Manual de uso y casos de prueba

* **CÃ³mo ejecutar**: `./build/neural_net_demo input.csv output.csv`
* **Casos de prueba**:

  * Test unitario de capa densa.
  * Test de funciÃ³n de activaciÃ³n ReLU.
  * Test de convergencia en dataset de ejemplo.

> *Personalizar rutas, comandos y casos reales.*

---

### 3. EjecuciÃ³n

> **Demo de ejemplo**: Video/demo alojado en `docs/demo.mp4`.
> Pasos:
>
> 1. Preparar datos de entrenamiento (formato CSV).
> 2. Ejecutar comando de entrenamiento.
> 3. Evaluar resultados con script de validaciÃ³n.

---

### 4. AnÃ¡lisis del rendimiento

* **MÃ©tricas de ejemplo**:

  * Iteraciones: 1000 Ã©pocas.
  * Tiempo total de entrenamiento: 2m30s.
  * PrecisiÃ³n final: 92.5%.
* **Ventajas/Desventajas**:

  * * CÃ³digo ligero y dependencias mÃ­nimas.
  * â€“ Sin paralelizaciÃ³n, rendimiento limitado.
* **Mejoras futuras**:

  * Uso de BLAS para multiplicaciones (JustificaciÃ³n).
  * Paralelizar entrenamiento por lotes (JustificaciÃ³n).

---

### 5. Trabajo en equipo

| Tarea                     | Miembro  | Rol                       |
| ------------------------- | -------- | ------------------------- |
| InvestigaciÃ³n teÃ³rica     | Alumno A | Documentar bases teÃ³ricas |
| DiseÃ±o de la arquitectura | Alumno B | UML y esquemas de clases  |
| ImplementaciÃ³n del modelo | Alumno C | CÃ³digo C++ de la NN       |
| Pruebas y benchmarking    | Alumno D | GeneraciÃ³n de mÃ©tricas    |
| DocumentaciÃ³n y demo      | Alumno E | Tutorial y video demo     |

> *Actualizar con tareas y nombres reales.*

---

### 6. Conclusiones

* **Logros**: Implementar NN desde cero, validar en dataset de ejemplo.
* **EvaluaciÃ³n**: Calidad y rendimiento adecuados para propÃ³sito acadÃ©mico.
* **Aprendizajes**: ProfundizaciÃ³n en backpropagation y optimizaciÃ³n.
* **Recomendaciones**: Escalar a datasets mÃ¡s grandes y optimizar memoria.

---

### 7. BibliografÃ­a

> *Actualizar con bibliografia utilizada, al menos 4 referencias bibliograficas y usando formato IEEE de referencias bibliograficas.*

---

### Licencia

Este proyecto usa la licencia **MIT**. Ver [LICENSE](LICENSE) para detalles.

---
